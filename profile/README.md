# Model Evaluation and Threat Research (METR)

METR is a research nonprofit that works on assessing whether cutting-edge AI systems could pose catastrophic risks to society.

We build the science of accurately assessing risks, so that humanity is informed before developing transformative AI systems.

Read more about our work [here](https://metr.org/).

# Our Software
- [Vivaria](https://github.com/METR/vivaria)
- [Public Task Suite](https://github.com/METR/public-tasks)
- [RE-Bench Task Suite](https://github.com/METR/ai-rd-tasks)
- Some of our open-source agents can be found at [github.com/poking-agents](https://github.com/poking-agents)

